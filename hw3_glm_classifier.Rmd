---
title: "hw3_glm for classifier"
author: "Cary Ni"
date: "2023-03-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(caret)
library(glmnet)
library(AppliedPredictiveModeling)
library(earth)
library(vip)
library(klaR)
library(MASS)
library(pROC)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
```

```{r}
# load the dataset, specifiy the factor variables
auto_df = read_csv("auto.csv", show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
  mutate(
    cylinders = as_factor(cylinders),
    origin = as_factor(origin),
    mpg_cat = as_factor(mpg_cat))
# data partition
set.seed(2023)
index_auto = createDataPartition(y = auto_df$mpg_cat, p = 0.7, list = FALSE)
```

## Feature plot for simple visualization 

```{r}
# simple visualization of the data
theme1 <- transparentTheme(trans = .4)
trellis.par.set(theme1)
featurePlot(x = auto_df[, 2:6],
            y = auto_df$mpg_cat, 
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "box", pch = "|",
            auto.key = list(columns = 2))
```

## Logistic regression (without penalty)

```{r}
# specify train method for logistic
ctrl_1 = trainControl(method = "repeatedcv",
                      summaryFunction = twoClassSummary,
                      classProbs = TRUE)
set.seed(1)
model_glm = train(x = auto_df[index_auto,1:7],
                  y = auto_df$mpg_cat[index_auto],
                  method = "glm",
                  metric = "ROC",
                  trControl = ctrl_1)
summary(model_glm)
contrasts(auto_df$mpg_cat)
# create confusion matrix (no specification for positive needed)
test_pred_prob = predict(model_glm, 
                         newdata = auto_df[-index_auto,],
                         type = "prob") %>% pull(high) %>% as_vector()
test_pred = rep("low", length(test_pred_prob))
# 50% chosen as threshold
test_pred[test_pred_prob>0.5] = "high"
confusionMatrix(data = as.factor(test_pred),
                reference = auto_df$mpg_cat[-index_auto])

```

At the 0.05 significance level, `cylinder4`, `horsepower`, `acceleration`, and `year` (treated as numerical instead of categorical here) are significant predictors of our outcome `mpg_cat`. The confusion matrix shows that the accuracy (overall fraction of correct predictions) is about 87.9% (95% CI: 80.6% to 93.2%). The no information rate is 50%, suggesting that if same class prediction are made for all observations, the model would be an accurate classifier 50% times in this scenario. A p-value around 0 indicates the model is statistically significantly better than null classifier. Since the specification for positive has no meaning when classifying either `low` or `high`, `low` is chosen as default "positive" class. Therefore, the model has 86.2% sensitive (true positives) and 89.7% specific (true negatives), with a positive predictive value of 89.3% and a negative predictive value of 86.7%. The kappa of 0.76 means that our inter-rater reliability is relatively high compared to the agreement by chance.

## Multivariate adaptive regression spline (MARS)

```{r}
set.seed(1)
# Set tuning parameters (30 as a reserved value for 4 significant and 6 non-significant predictors)
mars_grid = expand.grid(degree = 1:3, nprune = 2:30)
# Fit MARS model
mars_model = train(x = auto_df[index_auto,1:7],
                   y = auto_df$mpg_cat[index_auto], 
                   method = "earth",
                   tuneGrid = mars_grid,
                   metric = "ROC",
                   trControl = ctrl_1)
# Plot the model
plot(mars_model)
summary(mars_model)
# examine the importance of predictors
vip(mars_model$finalModel)
```

## Partition plot and linear discriminants in LDA

```{r}
# LDA based on every combination of two variables
partimat(mpg_cat ~ displacement + horsepower + weight + acceleration + year, 
         method = "lda", data = auto_df)
set.seed(1)
model_lda = train(mpg_cat~.,
                  data = auto_df[index_auto,],
                  method = "lda",
                  metric = "ROC",
                  trControl = ctrl_1)
# show the coefficient of LDA boundary
model_lda$finalModel$scaling
# Plot the linear discriminant from LDA
lda_fit = lda(mpg_cat ~ ., data = auto_df[index_auto,])
auto_lda_values = predict(lda_fit)
ldahist(auto_lda_values$x, g = auto_lda_values$class)
```

## Models comparsion

```{r}
# comparison based on resampling
res = resamples(list(Logistic = model_glm,
                     MARS = mars_model,
                     LDA = model_lda))
summary(res)
bwplot(res, metric = "ROC")

# comparsion based on test data (ROC curves)
lda_pred = predict(model_lda, newdata = auto_df[-index_auto,], type = "prob")[,2]
mars_pred = predict(mars_model, newdata = auto_df[-index_auto,], type = "prob")[,2]
log_pred = predict(model_glm, newdata = auto_df[-index_auto,], type = "prob")[,2]
roc_lda = roc(auto_df$mpg_cat[-index_auto], lda_pred)
roc_mars = roc(auto_df$mpg_cat[-index_auto], mars_pred)
roc_log = roc(auto_df$mpg_cat[-index_auto], log_pred)
plot(roc_lda, legacy.axes = TRUE)
plot(roc_mars, col = 2, add = TRUE)
plot(roc_log, col = 3, add = TRUE)
auc = c(roc_lda$auc[1], roc_mars$auc[1], roc_log$auc[1])
modelNames = c("lda","MARS","Logistic")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
col = 1:3, lwd = 2)

# 50% chosen as threshold for LDA
test_pred_lda = rep("low", length(lda_pred))
test_pred_lda[lda_pred>0.5] = "high"
confusionMatrix(data = as.factor(test_pred_lda),
                reference = auto_df$mpg_cat[-index_auto])
# 50% chosen as threshold for MARS
test_pred_mars = rep("low", length(mars_pred))
test_pred_mars[mars_pred>0.5] = "high"
confusionMatrix(data = as.factor(test_pred_mars),
                reference = auto_df$mpg_cat[-index_auto])
# 50% chosen as threshold for Logistic
test_pred_log = rep("low", length(log_pred))
test_pred_log[log_pred>0.5] = "high"
confusionMatrix(data = as.factor(test_pred_log),
                reference = auto_df$mpg_cat[-index_auto])
```

Based on the cross validation results on Linear Discriminant Analysis (LDA), Multivariate adaptive regression spline (MARS), and Logistic regression, the MARS model has highest mean area under curve (AUC) and thus be favored to make the predictions.

When fitting the three models above on the test dataset, Logistic regression model has highest AUC of 0.952, while LDA gives AUC of 0.933 and MARS has AUC of 0.912. Selecting 50% as the threshold of classification, both Logistic regression and MARS models give a misclassification rate of 0.121 (proportion of misclassified sample) while LDA gives a misclassification rate of 0.147. Thus it can be seen that Logistic regression model has best predictability in this test dataset. 
